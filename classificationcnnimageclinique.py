# -*- coding: utf-8 -*-
"""ClassificationCNNimageClinique.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18wzo48REFG3ml_MtXPcAef1j6DIO35t0
"""

# Commented out IPython magic to ensure Python compatibility.
#instalation librairie:
# %pip install SimpleITK

# Commented out IPython magic to ensure Python compatibility.

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sn
import pandas 
import sys, time, os
import SimpleITK as sitk

#from re import X
#importation data:
#(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()
#lecture du fichier excel de donnée:

def read_with_PANDAS(Nom_fichier):
    X=[]
    Y=[]
    df=pandas.read_csv(Nom_fichier,sep=";", header=0) ### problème avec xlsx non supporté 
    df.dropna(subset = ["PatientName"], inplace=True) #remove row if petient name is NaN
    X=df["PatientName"] #adresse image
    Y=df["Analyse visuel medecin (0-10)"] #note
    return X,Y

def main(directory,Nom_fichier):
    timeInit = time.time()
    Nimageouverte=0
    Nimagetraitees=0
    images=[]
    [liste_fichier,Note]=read_with_PANDAS(Nom_fichier)
    ############# lecture des fichiers image ###########
    for fichier in liste_fichier:
        Nimageouverte=Nimageouverte+1
        try:
            timeRMR1 = time.time()
            fichier=fichier+".nrrd"
            image_filepath = os.path.join(directory, fichier)
            images.append(sitk.GetArrayFromImage(sitk.ReadImage(image_filepath))) #ouvre l'image et la convertie en matrice numpy
        except RuntimeError:
            print ("--> Probleme avec l'importation et/ou le triatement d'image")
    print("\n")
    print("Nombre d'image total lue:"+str(Nimageouverte)+"\n")
    timefinal = time.time()
    TimeTotal = timefinal - timeInit
    print(u"Le traitement de l'ensemble des données c'est executée en " + str(TimeTotal) +" secondes")
    return images,Note

##########
directory="/content/images"
Nom_fichier="/content/QI_notation.csv"
[images,Note]=main(directory,Nom_fichier)

#convert images list to array
images=np.asarray(images)

plt.matshow(images[0])

#division des data 80, 20%
Nvaleurs=len(images)
N_seuil=int(Nvaleurs*0.8)

X_train=images[0:N_seuil] 
Y_train=Note[0:N_seuil]-1  #valeurs entre 1 et 10-> entre 0 et 9
X_test=images[N_seuil:(Nvaleurs)] 
Y_test=Note[N_seuil:(Nvaleurs)]-1  #valeurs entre 1 et 10-> entre 0 et 9

#(X_train, y_train) , (X_test, y_test)
print(len(X_test))
print(len(Y_test))
print(X_train[0].shape)

plt.matshow(X_train[5])
print(Y_train[5])

#increase database size:
#noise
def increase_noise:
  noisemap = create_noisemap() 
  noisy = image + np.random.poisson(noisemap)  

#def poisson(img):
    vals = len(np.unique(img))
    vals = 2 ** np.ceil(np.log2(vals))
    return np.random.poisson(img * vals) / float(vals)

#convolutionnal neural network:

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(8, 8), activation='relu', input_shape=(288,432,1)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(filters=32, kernel_size=(8, 8), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

cnn.fit(X_train, Y_train, epochs=10)

cnn.summary()

#performance du model
from sklearn.metrics import confusion_matrix , classification_report


cnn.evaluate(X_test,Y_test)
y_predicted = cnn.predict(X_test)
y_predicted_labels = [np.argmax(i) for i in y_predicted]

#confusion matrix:
cm = tf.math.confusion_matrix(labels=Y_test,predictions=y_predicted_labels)

plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

# rapport de classification:

print("Classification Report: \n", classification_report(Y_test, y_predicted_labels))